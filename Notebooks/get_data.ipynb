{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import etree\n",
    "from time import sleep\n",
    "import cssselect\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants for use later\n",
    "BASE_URL = \"https://www.mailleartisans.org/weaves/weavedisplay.php?key=\"\n",
    "FIRST_ARTICLE = 1\n",
    "LAST_ARTICLE = 1487"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create function to get multiple articles\n",
    "def get_articles(articles) -> dict:\n",
    "    out = dict()\n",
    "    for i in articles:\n",
    "        print(f\"Getting article {i}\")\n",
    "        response = requests.get(f\"{BASE_URL}{i}\")\n",
    "        if response.status_code == 200:\n",
    "            out[i] = response.content\n",
    "            print(f\"Got article {i} sleeping for 10 seconds.\")\n",
    "        else:\n",
    "            out[i] = 'failure'\n",
    "            print(f\"Could not get article {i} sleeping for 10 seconds.\")\n",
    "        sleep(10)\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Getting Data From Articles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Get Test Articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting article 1\n",
      "Got article 1 sleeping for 10 seconds.\n",
      "Getting article 2\n",
      "Got article 2 sleeping for 10 seconds.\n",
      "Getting article 6\n",
      "Got article 6 sleeping for 10 seconds.\n",
      "Getting article 11\n",
      "Got article 11 sleeping for 10 seconds.\n",
      "Getting article 189\n",
      "Got article 189 sleeping for 10 seconds.\n",
      "Getting article 1086\n",
      "Got article 1086 sleeping for 10 seconds.\n",
      "Getting article 1173\n",
      "Got article 1173 sleeping for 10 seconds.\n",
      "Getting article 1488\n",
      "Got article 1488 sleeping for 10 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Get some articles and store them to avoid repeated calls to the website\n",
    "\n",
    "to_get = [\n",
    "    1,    # single AR no Min no Max\n",
    "    2,    # multi AR no Min no Max\n",
    "    6,    # single AR no Max\n",
    "    11,   # multi AR no Max\n",
    "    189,  # No ARs given\n",
    "    1086, # Single ar all ARs given\n",
    "    1173, # multi AR all values given\n",
    "    1488, # Error page with No AR values\n",
    "]\n",
    "\n",
    "arts = get_articles(to_get)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Single Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weave Title: Trizantine\n",
      "Max AR: , Ideal AR: 5.2, Min AR: \n",
      "Date Uploaded: May 3, 2008, 6:36 pm, Last Edited: June 22, 2017, 11:45 am\n"
     ]
    }
   ],
   "source": [
    "# Select Article\n",
    "article = arts[1]\n",
    "\n",
    "# Convert first article into an etree\n",
    "soup = BeautifulSoup(article, 'html.parser')\n",
    "dom = etree.HTML(str(soup.html))\n",
    "\n",
    "\n",
    "\n",
    "# Parse etree to find values of interest\n",
    "\n",
    "## Determine if an article exists\n",
    "if len(dom.xpath('/html/body/div[5]/div/h2')) > 0:\n",
    "        print('No weave here')\n",
    "else:\n",
    "    ## Weave Title\n",
    "    path = '/html/body/div[5]/div/table/tr/td[2]/div[2]/font'\n",
    "    title = dom.xpath(path)[0].text\n",
    "    print(f'Weave Title: {title}')\n",
    "\n",
    "    ## Get AR Values\n",
    "\n",
    "    ### Get AR val string from page\n",
    "    path = '/html/body/div[5]/div/table/tr/td[1]/table/tr[2]/td/div[not(@class)][2]//text()'\n",
    "    ar_val_string = ' '.join([i for i in dom.xpath(path) if i != '\\n'][:-1])\n",
    "\n",
    "    ### Extract max ar value from ar string\n",
    "    max_ar = re.search('%s(.*)%s' % ('Max. AR :', ' Ideal AR :'), ar_val_string).group(1).replace(' ', '')\n",
    "\n",
    "    ### Extract ideal ar value from ar string\n",
    "    ideal_ar = re.search('%s(.*)%s' % (' Ideal AR :', 'Min. AR :'), ar_val_string).group(1).replace(' ', '')\n",
    "\n",
    "    ### Extract min ar value from ar string\n",
    "    min_ar = re.search('%s(.*)' % ('Min. AR :'), ar_val_string).group(1).replace(' ', '')\n",
    "\n",
    "    ### Print ar values from ar string\n",
    "    print(f'Max AR: {max_ar}, Ideal AR: {ideal_ar}, Min AR: {min_ar}')\n",
    "\n",
    "    ### Get all dates from page\n",
    "    date_string = ''.join(results).replace('\\n', '')\n",
    "\n",
    "    ### Get the upload date\n",
    "    date_uploaded = re.search('%s(.*)%s' % ('Date Uploaded', 'Last Edited'), date_string).group(1).strip()\n",
    "\n",
    "    ### Get the last edited date\n",
    "    last_edited = re.search('%s(.*)' % ('Last Edited'), date_string).group(1).strip()\n",
    "\n",
    "    ### Print out the dates\n",
    "    print(f'Date Uploaded: {date_uploaded}, Last Edited: {last_edited}')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xpath Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path results: ['\\n', 'Date Uploaded', '\\n              May 3, 2008, 6:36 pm', '\\n', 'Last Edited', '\\n              June 22, 2017, 11:45 am\\n              \\n            ']\n",
      "Selected Element at path results\n",
      "\n",
      "Children of selected element at path results:\n",
      "\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# New goal get date data\n",
    "\n",
    "path = '/html/body/div[5]/div/table/tr/td[1]/table/tr[2]/td/div[not(@class)][3]//text()'\n",
    "\n",
    "num = 0\n",
    "results = dom.xpath(path)\n",
    "result = results[num]\n",
    "\n",
    "print(f\"Current path results: {dom.xpath(path)}\")\n",
    "\n",
    "print(f\"Selected Element at path results{result}\")\n",
    "\n",
    "print(\"Children of selected element at path results:\")\n",
    "\n",
    "for i in result:\n",
    "    print('\\t',i, sep='')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test All Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article: 1\n",
      "Weave Title: Trizantine\n",
      "Max AR: , Ideal AR: 5.2, Min AR: \n",
      "Date Uploaded: May 3, 2008, 6:36 pm, Last Edited: June 22, 2017, 11:45 am\n",
      "\n",
      "Article: 2\n",
      "Weave Title: Hizashi 1\n",
      "Max AR: , Ideal AR: 8.0|3.0, Min AR: \n",
      "Date Uploaded: May 3, 2008, 6:36 pm, Last Edited: June 22, 2017, 11:45 am\n",
      "\n",
      "Article: 6\n",
      "Weave Title: European 4 in 1\n",
      "Max AR: , Ideal AR: 4.0, Min AR: 2.83\n",
      "Date Uploaded: May 3, 2008, 6:36 pm, Last Edited: June 22, 2017, 11:45 am\n",
      "\n",
      "Article: 11\n",
      "Weave Title: Dragonscale\n",
      "Max AR: , Ideal AR: 3.9|6.1, Min AR: 3.7|5.7\n",
      "Date Uploaded: May 3, 2008, 6:36 pm, Last Edited: June 22, 2017, 11:45 am\n",
      "\n",
      "Article: 189\n",
      "Weave Title: Captive Persian Round Sheet\n",
      "Max AR: , Ideal AR: , Min AR: \n",
      "Date Uploaded: May 3, 2008, 6:36 pm, Last Edited: June 22, 2017, 11:45 am\n",
      "\n",
      "Article: 1086\n",
      "Weave Title: Cloudy Day\n",
      "Max AR: 4.5, Ideal AR: 3.9, Min AR: 3.6\n",
      "Date Uploaded: May 3, 2008, 6:36 pm, Last Edited: June 22, 2017, 11:45 am\n",
      "\n",
      "Article: 1173\n",
      "Weave Title: Onering\n",
      "Max AR: 3.0|6.9, Ideal AR: 2.9|5.0, Min AR: 2.7|3.0\n",
      "Date Uploaded: May 3, 2008, 6:36 pm, Last Edited: June 22, 2017, 11:45 am\n",
      "\n",
      "Article: 1488\n",
      "No weave here\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Iterate through all articles\n",
    "for key, value in arts.items():\n",
    "    print(f'Article: {key}')\n",
    "\n",
    "    # Convert article to etree\n",
    "    soup = BeautifulSoup(value, 'html.parser')\n",
    "    dom = etree.HTML(str(soup.html))\n",
    "\n",
    "    # Parse etree to find values of interest\n",
    "\n",
    "    ## Determine if an article exists\n",
    "    if len(dom.xpath('/html/body/div[5]/div/h2')) > 0:\n",
    "            print('No weave here')\n",
    "    else:\n",
    "        ## Weave Title\n",
    "        path = '/html/body/div[5]/div/table/tr/td[2]/div[2]/font'\n",
    "        title = dom.xpath(path)[0].text\n",
    "        print(f'Weave Title: {title}')\n",
    "\n",
    "        ## Get AR Values\n",
    "\n",
    "        ### Get AR val string from page\n",
    "        path = '/html/body/div[5]/div/table/tr/td[1]/table/tr[2]/td/div[not(@class)][2]//text()'\n",
    "        ar_val_string = ' '.join([i for i in dom.xpath(path) if i != '\\n'][:-1])\n",
    "\n",
    "        ### Extract max ar value from ar string\n",
    "        max_ar = re.search('%s(.*)%s' % ('Max. AR :', ' Ideal AR :'), ar_val_string).group(1).replace(' ', '')\n",
    "\n",
    "        ### Extract ideal ar value from ar string\n",
    "        ideal_ar = re.search('%s(.*)%s' % (' Ideal AR :', 'Min. AR :'), ar_val_string).group(1).replace(' ', '')\n",
    "\n",
    "        ### Extract min ar value from ar string\n",
    "        min_ar = re.search('%s(.*)' % ('Min. AR :'), ar_val_string).group(1).replace(' ', '')\n",
    "\n",
    "        ### Print ar values from ar string\n",
    "        print(f'Max AR: {max_ar}, Ideal AR: {ideal_ar}, Min AR: {min_ar}')\n",
    "\n",
    "        ### Get all dates from page\n",
    "        date_string = ''.join(results).replace('\\n', '')\n",
    "\n",
    "        ### Get the upload date\n",
    "        date_uploaded = re.search('%s(.*)%s' % ('Date Uploaded', 'Last Edited'), date_string).group(1).strip()\n",
    "\n",
    "        ### Get the last edited date\n",
    "        last_edited = re.search('%s(.*)' % ('Last Edited'), date_string).group(1).strip()\n",
    "\n",
    "        ### Print out the dates\n",
    "        print(f'Date Uploaded: {date_uploaded}, Last Edited: {last_edited}')\n",
    "    \n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
